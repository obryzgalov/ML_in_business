{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5616bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\u187s\\anaconda3\\lib\\site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install razdel # сегоментация русскоязычного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8928267",
   "metadata": {},
   "source": [
    "сегментация русскоязычного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01be3581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pymorphy2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b9a0f1",
   "metadata": {},
   "source": [
    "морфологический анализатор для русского языка, написанный на языке Python и использующий словари из OpenCorpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1ed6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Using cached pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (63.4.1)\n",
      "Collecting pandas>=2.0.0\n",
      "  Using cached pandas-2.0.3-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "Requirement already satisfied: funcy in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.9.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\u187s\\anaconda3\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "Installing collected packages: joblib, pandas, pyLDAvis\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.4\n",
      "    Uninstalling pandas-1.4.4:\n",
      "      Successfully uninstalled pandas-1.4.4\n",
      "Successfully installed joblib-1.3.1 pandas-2.0.3 pyLDAvis-3.4.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyLDAvis \n",
    "\"\"\"\n",
    "Ещё одним вариантом визуализации результатов работы алгоритма LDA в Python является модуль pyLDAvis, который позволяет\n",
    "сохранять полученную тематическую модель в виде отдельного html файла для дальнейшей интерактивной работы с ней.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5700f5",
   "metadata": {},
   "source": [
    "# ДЗ №2\n",
    "\n",
    "1) Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "\n",
    "2) Повторить п.2, но используя уже не медиану, а max \n",
    "\n",
    "3) (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "\n",
    "4) Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "\n",
    "5) Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a1aaf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\u187s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6742560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "#предобработка текстов\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "from razdel import tokenize # https://github.com/natasha/razdel\n",
    "import pymorphy2  \n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3938a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>Главный тренер «Кубани» Юрий Красножан прокомм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>Решением попечительского совета владивостокско...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент...\n",
       "3    4898  Главный тренер «Кубани» Юрий Красножан прокомм...\n",
       "4    4899  Решением попечительского совета владивостокско..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# прочитаем файл с перечнем статей, поданный в формате id/содержание\n",
    "news = pd.read_csv(\"C:/Users/u187s/LEARNING/MLB/HWK_2/articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beac52b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u101138</td>\n",
       "      <td>[5933, 6186, 5055, 6977, 5206, 488389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u108248</td>\n",
       "      <td>[707, 1144, 2532, 2928, 3133, 324592]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]\n",
       "3  u101138          [5933, 6186, 5055, 6977, 5206, 488389]\n",
       "4  u108248           [707, 1144, 2532, 2928, 3133, 324592]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузим пользователей и списки последних прочитанных статей по doc_id\n",
    "users = pd.read_csv('C:/Users/u187s/LEARNING/MLB/HWK_2/users_articles.csv')\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "854723f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "# Необходимо получить векторные представления пользователей по прочитанным ими новостям и самих новостям:\n",
    "\n",
    "stopword_ru = stopwords.words('russian')\n",
    "print(len(stopword_ru))\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a01d45b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('C:/Users/u187s/LEARNING/MLB/HWK_2/stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b4433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str): #isinstance функция для проверки принодлежности обьекта конкретному типу.\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower() \n",
    "    #меняем гегистр всех знаков\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t') \n",
    "    # удаление символов новой строки ('\\n'), возврата каретки ('\\r') и табуляции ('\\t') с начала и конца строки текста.\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "    \"\"\"\n",
    "    Данная строка кода использует модуль re (регулярные выражения) для замены определенных шаблонов подстрок в тексте\n",
    "    на пустую строку.\n",
    "    Используя функцию `re.sub()`, мы передаем три аргумента: регулярное выражение,\n",
    "    заменитель и исходную строку.\n",
    "\n",
    "    Регулярное выражение `-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n` содержит три шаблона, разделенных вертикальной чертой (`|`).    \n",
    "    Каждый найденный шаблон заменяется на пустую строку (`''`) в коде.\n",
    "\n",
    "    Данная строка кода заменяет все вхождения указанных шаблонов в исходном тексте на пустую строку.\n",
    "    Это позволяет удалить эти шаблоны из текста.\n",
    "    \n",
    "    \"\"\"\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    \"\"\"\n",
    "    также удвление приведенных шаблонов из текста и их замена на строку\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    \"\"\"\n",
    "    данная строка кода заменяет все вхождения шаблонов символов,\n",
    "    связанных с разделителями строк и пробелами, на пробел. Это позволяет привести текст к единому формату,\n",
    "    где эти символы заменены на пробелы\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \"\"\"\n",
    "     данная строка кода заменяет мягкий дефис и пробельные символы на пробелы,\n",
    "     а затем удаляет пробельные символы из начала и конца текста.\n",
    "     \n",
    "     по итогу чистка текста это последовательность операций:\n",
    "     1. все переводим в \"текст\"\n",
    "     2. нижний регистр\n",
    "     3. разбиение строки на слова, разделение их пустой строкой- как бы вертикальный список\n",
    "     4. очистка от символов и их замена на строку\n",
    "     5. удаление переносов и пробелов с помощью text.strip()\n",
    "    \"\"\"\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cc8da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. \n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c42f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. (приведение к словарной форме)\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33b64e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели:\n",
    "\n",
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6543983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nЧто такое common_dictionary и как он выглядит\\n\\ncommon_dictionary[20]\\n\\nтаким образом можно вызвать любое слово из словаря\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Что такое common_dictionary и как он выглядит\n",
    "\n",
    "common_dictionary[20]\n",
    "\n",
    "таким образом можно вызвать любое слово из словаря\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea87b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем обучение:\n",
    "#%%time\n",
    "from gensim.models import LdaModel\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)#, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76d652b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb7546b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.030961791),\n",
       " (8, 0.18403733),\n",
       " (9, 0.05148564),\n",
       " (10, 0.13074577),\n",
       " (18, 0.43100443),\n",
       " (24, 0.15486085)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03c4943d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: фонд млрд область рейтинг миллиард рубль губернатор\n",
      "topic_1: километр берег оперативно мексиканский повторяться покой telegraphn\n",
      "topic_2: женщина мужчина остров египет японский разместить вуз\n",
      "topic_3: газ рынок снижение журнал сша товар американский\n",
      "topic_4: поверхность северный высота фестиваль китай южный бомба\n",
      "topic_5: тело смерть мужчина произойти женщина пилот инцидент\n",
      "topic_6: год это который россия nn научный российский\n",
      "topic_7: ii юрист литва оплачивать арабский миля калининградский\n",
      "topic_8: год это новый который сша первый исследование\n",
      "topic_9: год ребёнок который nn это исследование семья\n",
      "topic_10: египетский лестница кит покупатель мвд натуральный радикально\n",
      "topic_11: земля температура день болезнь тыс экипаж изз\n",
      "topic_12: это который свой nn россия страна год\n",
      "topic_13: год военный который это человек риск жизнь\n",
      "topic_14: ракета компания станция продукция министерство суд выделить\n",
      "topic_15: это который год млрд банк мочь российский\n",
      "topic_16: налог двигатель форум испытание млн пространство парк\n",
      "topic_17: иран медик ливия исполнить иракский чен присудить\n",
      "topic_18: это очень говорить мочь всё выяснить рост\n",
      "topic_19: город журнал который район статья пострадать аэропорт\n",
      "topic_20: производитель энергия лагерь выстрел малое снг перо\n",
      "topic_21: год который человек это область nn место\n",
      "topic_22: свердловский компенсация эндрю уильям прага склонный чешский\n",
      "topic_23: турция турецкий офицер памятник супруг конструкция это\n",
      "topic_24: украина украинский киев это гражданин россия год\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8573831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#пишем функцию, которая будет возвращать векторное представление новости:\n",
    "#text = news['title'].iloc[0]\n",
    "\n",
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a64d114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507308</td>\n",
       "      <td>0.128848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.123839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0  topic_1   topic_2   topic_3  topic_4  topic_5  topic_6  \\\n",
       "0       6  0.000000      0.0  0.000000  0.000000      0.0      0.0      0.0   \n",
       "1    4896  0.000000      0.0  0.031944  0.000000      0.0      0.0      0.0   \n",
       "2    4897  0.000000      0.0  0.000000  0.031609      0.0      0.0      0.0   \n",
       "3    4898  0.019246      0.0  0.000000  0.000000      0.0      0.0      0.0   \n",
       "4    4899  0.123839      0.0  0.327125  0.000000      0.0      0.0      0.0   \n",
       "\n",
       "   topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0      0.0  0.000000  ...  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "1      0.0  0.000000  ...  0.061631       0.0  0.000000  0.000000  0.000000   \n",
       "2      0.0  0.182798  ...  0.000000       0.0  0.000000  0.431157  0.000000   \n",
       "3      0.0  0.308741  ...  0.000000       0.0  0.000000  0.507308  0.128848   \n",
       "4      0.0  0.000000  ...  0.000000       0.0  0.029735  0.062992  0.000000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0       0.0       0.0       0.0  0.000000  \n",
       "1       0.0       0.0       0.0       0.0  0.000000  \n",
       "2       0.0       0.0       0.0       0.0  0.155176  \n",
       "3       0.0       0.0       0.0       0.0  0.000000  \n",
       "4       0.0       0.0       0.0       0.0  0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3b443b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#векторные представления пользователей:\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afcdebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e250157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.14263247, 0.        , 0.        , 0.26836744,\n",
       "       0.        , 0.        , 0.        , 0.08507032, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.31316391, 0.01583997, 0.        , 0.16339324])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90f118",
   "metadata": {},
   "source": [
    "# ДЗ выполнение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aca999d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "\n",
    "def get_user_embedding_mean(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    #print(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector\n",
    "\n",
    "def get_user_embedding_median(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    #print(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector\n",
    "\n",
    "def get_user_embedding_max(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    #print(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "301f761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.142565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.208288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070446</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.098786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.019085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>0.211021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098630</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.126237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.011668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0  u105138  0.008607  0.000000  0.014783  0.000000  0.003802  0.007187   \n",
       "1  u108690  0.005086  0.001691  0.004073  0.005377  0.000000  0.010307   \n",
       "2  u108339  0.019085  0.000000  0.000000  0.009709  0.002451  0.035059   \n",
       "\n",
       "    topic_6  topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  0.142565      0.0  0.116962  ...  0.065907  0.000000       0.0  0.000000   \n",
       "1  0.208288      0.0  0.010382  ...  0.115645  0.000000       0.0  0.070446   \n",
       "2  0.211021      0.0  0.025751  ...  0.098630  0.004865       0.0  0.008983   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0  0.051043       0.0  0.078017   0.00264  0.018218  0.128400  \n",
       "1  0.017517       0.0  0.069127   0.00000  0.011893  0.098786  \n",
       "2  0.126237       0.0  0.099202   0.00000  0.002825  0.011668  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#получим эмбединги для всех пользователей и проверим их качество на конкретной downstream-задаче:\n",
    "user_embeddings_mean = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_mean(x), 1)])\n",
    "user_embeddings_mean.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings_mean['uid'] = users['uid'].values\n",
    "user_embeddings_mean = user_embeddings_mean[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings_mean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "486e11cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.049875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.201260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.110034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   topic_0  topic_1  topic_2  topic_3  topic_4   topic_5   topic_6  \\\n",
       "0  u105138  0.000000      0.0      0.0      0.0      0.0  0.000000  0.100012   \n",
       "1  u108690  0.000000      0.0      0.0      0.0      0.0  0.000000  0.211435   \n",
       "2  u108339  0.016239      0.0      0.0      0.0      0.0  0.021426  0.201260   \n",
       "\n",
       "   topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0      0.0  0.077730  ...  0.000000       0.0       0.0    0.0000  0.000000   \n",
       "1      0.0  0.000000  ...  0.091038       0.0       0.0    0.0626  0.008881   \n",
       "2      0.0  0.018033  ...  0.077949       0.0       0.0    0.0000  0.110034   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0  0.034745       0.0  0.000000  0.000000  \n",
       "1       0.0  0.042217       0.0  0.005985  0.049875  \n",
       "2       0.0  0.091271       0.0  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings_median = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_median(x), 1)])\n",
    "user_embeddings_median.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings_median['uid'] = users['uid'].values\n",
    "user_embeddings_median = user_embeddings_median[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings_median.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7859374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.043121</td>\n",
       "      <td>0.394285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313164</td>\n",
       "      <td>0.01584</td>\n",
       "      <td>0.109310</td>\n",
       "      <td>0.607008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.017823</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.032264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>0.336639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196915</td>\n",
       "      <td>0.052146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170825</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.294637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.044921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035824</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>0.111244</td>\n",
       "      <td>0.372324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206815</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.304479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165631</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.047303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0  u105138  0.051641  0.000000  0.088700  0.000000  0.022810  0.043121   \n",
       "1  u108690  0.017823  0.010147  0.024435  0.032264  0.000000  0.032576   \n",
       "2  u108339  0.044921  0.000000  0.000000  0.035824  0.014708  0.111244   \n",
       "\n",
       "    topic_6  topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  0.394285      0.0  0.314513  ...  0.220558  0.000000       0.0  0.000000   \n",
       "1  0.336639      0.0  0.046962  ...  0.298279  0.000000       0.0  0.196915   \n",
       "2  0.372324      0.0  0.092201  ...  0.206815  0.029187       0.0  0.053900   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0  0.220939       0.0  0.313164   0.01584  0.109310  0.607008  \n",
       "1  0.052146       0.0  0.170825   0.00000  0.033259  0.294637  \n",
       "2  0.304479       0.0  0.165631   0.00000  0.016948  0.047303  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings_max = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_max(x), 1)])\n",
    "user_embeddings_max.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings_max['uid'] = users['uid'].values\n",
    "user_embeddings_max = user_embeddings_max[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings_max.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38c41424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# попробуем обучить модель. Загрузим нашу разметку:\n",
    "target = pd.read_csv('C:/Users/u187s/LEARNING/MLB/HWK_2/users_churn.csv')\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7db167fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = pd.merge(user_embeddings_mean, target, 'left')\n",
    "\n",
    "X_median = pd.merge(user_embeddings_median, target, 'left')\n",
    "\n",
    "X_max = pd.merge(user_embeddings_max, target, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0553c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_mean_train, X_mean_test, y_mean_train, y_mean_test = train_test_split(X_mean[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X_mean['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "029139c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_median_train, X_median_test, y_median_train, y_median_test = train_test_split(X_median[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X_median['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d31c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max_train, X_max_test, y_max_train, y_max_test = train_test_split(X_max[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X_max['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11a0a9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_mean = LogisticRegression()\n",
    "#обучим \n",
    "logreg_mean.fit(X_mean_train, y_mean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad901b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_median = LogisticRegression()\n",
    "#обучим \n",
    "logreg_median.fit(X_median_train, y_median_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c93c4f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_max = LogisticRegression()\n",
    "#обучим \n",
    "logreg_max.fit(X_max_train, y_max_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "782846d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11638453, 0.03420878, 0.22226366, 0.26147397, 0.02891024,\n",
       "       0.09234556, 0.24190505, 0.06324814, 0.22810525, 0.24579717])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_mean = logreg_mean.predict_proba(X_mean_test)[:, 1]\n",
    "preds_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b64906ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1854918 , 0.03911334, 0.41237093, 0.20042129, 0.0467526 ,\n",
       "       0.11214018, 0.22934422, 0.04852276, 0.08045623, 0.2050416 ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_median = logreg_median.predict_proba(X_median_test)[:, 1]\n",
    "preds_median[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97474380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02007045, 0.00365139, 0.69759375, 0.32718245, 0.00812731,\n",
       "       0.03603509, 0.08013866, 0.04093922, 0.02715155, 0.19429831])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_max = logreg_max.predict_proba(X_max_test)[:, 1]\n",
    "preds_max[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ba2013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['mean', 'median', 'max']\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "roc_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27fcd8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.225925, F-Score=0.587, Precision=0.506, Recall=0.698\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем Precision, Recall, F_score:\n",
    "precision_mean, recall_mean, thresholds_mean = precision_recall_curve(y_mean_test, preds_mean)\n",
    "fscore_mean = (2 * precision_mean * recall_mean) / (precision_mean + recall_mean)\n",
    "# locate the index of the largest f score\n",
    "ix_mean = np.argmax(fscore_mean)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds_mean[ix_mean], \n",
    "                                                                        fscore_mean[ix_mean],\n",
    "                                                                        precision_mean[ix_mean],\n",
    "                                                                        recall_mean[ix_mean]))\n",
    "precision.append(precision_mean[ix_mean])\n",
    "recall.append(recall_mean[ix_mean])\n",
    "fscore.append(fscore_mean[ix_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59c91575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.771111, F-Score=nan, Precision=0.000, Recall=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u187s\\AppData\\Local\\Temp\\ipykernel_18532\\3521988928.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  fscore_median = (2 * precision_median * recall_median) / (precision_median + recall_median)\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем Precision, Recall, F_score:\n",
    "precision_median, recall_median, thresholds_median = precision_recall_curve(y_median_test, preds_median)\n",
    "fscore_median = (2 * precision_median * recall_median) / (precision_median + recall_median)\n",
    "# locate the index of the largest f score\n",
    "ix_median = np.argmax(fscore_median)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds_median[ix_median], \n",
    "                                                                        fscore_median[ix_median],\n",
    "                                                                        precision_median[ix_median],\n",
    "                                                                        recall_median[ix_median]))\n",
    "precision.append(precision_median[ix_median])\n",
    "recall.append(recall_median[ix_median])\n",
    "fscore.append(fscore_median[ix_median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e392461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.314471, F-Score=0.751, Precision=0.722, Recall=0.784\n"
     ]
    }
   ],
   "source": [
    "#Рассчитаем Precision, Recall, F_score:\n",
    "precision_max, recall_max, thresholds_max = precision_recall_curve(y_max_test, preds_max)\n",
    "fscore_max = (2 * precision_max * recall_max) / (precision_max + recall_max)\n",
    "# locate the index of the largest f score\n",
    "ix_max = np.argmax(fscore_max)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds_max[ix_max], \n",
    "                                                                        fscore_max[ix_max],\n",
    "                                                                        precision_max[ix_max],\n",
    "                                                                        recall_max[ix_max]))\n",
    "precision.append(precision_max[ix_max])\n",
    "recall.append(recall_max[ix_max])\n",
    "fscore.append(fscore_max[ix_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e27bf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8995895110180826\n",
      "median: 0.9472039072039072\n",
      "max: 0.9646839932554218\n"
     ]
    }
   ],
   "source": [
    "roc_auc_mean = roc_auc_score(y_mean_test, preds_mean)\n",
    "print(f'mean: {roc_auc_mean}')\n",
    "roc_auc.append(roc_auc_mean)\n",
    "\n",
    "roc_auc_median = roc_auc_score(y_median_test, preds_median)\n",
    "print(f'median: {roc_auc_median}')\n",
    "roc_auc.append(roc_auc_median)\n",
    "\n",
    "roc_auc_max = roc_auc_score(y_max_test, preds_max)\n",
    "print(f'max: {roc_auc_max}')\n",
    "roc_auc.append(roc_auc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ef476e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.column_stack([model, precision, recall, fscore, roc_auc]), \n",
    "                               columns=['model', 'precision', 'recall', 'fscore', 'roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4e2a96b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.5059171597633136</td>\n",
       "      <td>0.6979591836734694</td>\n",
       "      <td>0.5866209262435678</td>\n",
       "      <td>0.8995895110180826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>median</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9472039072039072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max</td>\n",
       "      <td>0.7218045112781954</td>\n",
       "      <td>0.7836734693877551</td>\n",
       "      <td>0.7514677103718199</td>\n",
       "      <td>0.9646839932554218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model           precision              recall              fscore  \\\n",
       "0    mean  0.5059171597633136  0.6979591836734694  0.5866209262435678   \n",
       "1  median                 0.0                 0.0                 nan   \n",
       "2     max  0.7218045112781954  0.7836734693877551  0.7514677103718199   \n",
       "\n",
       "              roc_auc  \n",
       "0  0.8995895110180826  \n",
       "1  0.9472039072039072  \n",
       "2  0.9646839932554218  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d207b",
   "metadata": {},
   "source": [
    "Самый хороший результат показала модель, в которую были поданы максимальные значения векторов. Возможно это связано с тем, что мы берем максимально характеризующие пользователя вектора статей (тем самым \"сужая допуски\" модели при обучении) из чего она делает более точные прогнозы так как базово обучалась на наиболее подходящих значениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee2728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f619594b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18532\\399856767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcnf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m plot_confusion_matrix(cnf_matrix, classes=['Non-Churn', 'churn'],\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "#мы уже нашли ранее \"оптимальный\" порог, когда максимизировали f_score\n",
    "font = {'size' : 15}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, preds>thresholds[ix])\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Non-Churn', 'churn'],\n",
    "                      title='Confusion matrix')\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ea661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
